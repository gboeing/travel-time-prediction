% !TeX program = pdflatex
% Minimally-Congested Travel Time Prediction from Sparse Open Data
% Authors: Geoff Boeing and Yuquan Zhou
% Web: https://geoffboeing.com/
% Repo: https://github.com/gboeing/travel-time-prediction

\newcommand{\myname}{Geoff Boeing and Yuquan Zhou}
\newcommand{\myemail}{boeing@usc.edu}
\newcommand{\myaffiliation}{University of Southern California}
\newcommand{\paperdate}{2025}
\newcommand{\papertitle}{Minimally-Congested Travel Time Prediction from Sparse Open Data}
\newcommand{\papercitation}{Boeing, G. and Y. Zhou. \paperdate. \papertitle. Under review at \emph{Journal Name}.}
\newcommand{\paperkeywords}{Urban Planning, Transportation, Data Science}

\RequirePackage[l2tabu,orthodox]{nag} % warn if using any obsolete or outdated commands
\documentclass[12pt,letterpaper]{article} % document style

% load encoding and font packages for pdflatex, in order
\usepackage[T1]{fontenc}    % output 8-bit encoded fonts
\usepackage[utf8]{inputenc} % allow input of utf-8 encoded characters
\usepackage{ebgaramond}     % document's serif font
\usepackage{tgheros}        % document's sans serif font

% load babel, csquotes, and microtype in order
\usepackage[USenglish]{babel} % auto-regionalize hyphens, quote marks, etc
\usepackage[strict,autostyle]{csquotes} % smart and nestable quote marks
\usepackage[babel=true]{microtype} % enable micro-typographic adjustments

% import everything else
\usepackage{amsmath} % additional mathematical typesetting features
\usepackage{authblk} % footnote-style author/affiliation info
\usepackage{booktabs} % better looking tables
\usepackage{caption} % custom figure/table caption styles
\usepackage{datetime} % enable formatting of date output
\usepackage[final]{draftwatermark} % watermark paper as a draft
\usepackage{endnotes} % enable endnotes
\usepackage{geometry} % configure page dimensions and margins
\usepackage{graphicx} % better inclusion of graphics
\usepackage{natbib} % author-year citations w/ bibtex, including textual and parenthetical
\usepackage{rotating} % rotate wide tables or figures on a page to make them landscape
\usepackage{setspace} % configure spacing between lines
\usepackage{titlesec} % custom section and subsection heading
\usepackage{url} % make nice line-breakble urls

% load hyperref/orcidlink last for compatibility
\usepackage{hyperref} % enable hyperlinks and pdf metadata
\usepackage{orcidlink} % provide orcid logo and link

% print only the month and year when using \today
\newdateformat{monthyeardate}{\monthname[\THEMONTH] \THEYEAR}

% location of figure files, via graphicx package
\graphicspath{{.}}

% configure the page layout, via geometry package
\geometry{
    paper=letterpaper, % paper size
    top=3.8cm, % margin sizes
    bottom=3.8cm,
    left=4cm,
    right=4cm}
\setstretch{1} % line spacing
\clubpenalty=10000 % prevent orphans
\widowpenalty=10000 % prevent widows

% set section/subsection headings as the sans serif font, via titlesec package
\titleformat{\section}{\normalfont\sffamily\large\bfseries\color{black}}{\thesection.}{0.3em}{}
\titleformat{\subsection}{\normalfont\sffamily\small\bfseries\color{black}}{\thesubsection.}{0.3em}{}
\titleformat{\subsubsection}{\normalfont\sffamily\small\color{black}}{\thesubsubsection.}{0.3em}{}

% make figure/table captions sans-serif small font
\captionsetup{font={footnotesize,sf},labelfont=bf,labelsep=period}

% configure pdf metadata and link handling, via hyperref package
\hypersetup{
    pdfauthor={\myname},
    pdftitle={\papertitle},
    pdfsubject={\papertitle},
    pdfkeywords={\paperkeywords},
    pdffitwindow=true, % window fit to page when opened
    breaklinks=true, % break links that overflow horizontally
    colorlinks=false, % remove link color
    pdfborder={0 0 0} % remove link border
}

\begin{document}

\title{\papertitle}
\author[]{Redacted for review}%{\myname}
\affil[]{Redacted for review}%{\myaffiliation}
\date{}%\paperdate}

\maketitle

\begin{abstract}

Travel time prediction is central to accessibility analyses, sustainable transportation infrastructure provision, and active transportation interventions. However, calculating accurate travel times, especially for driving, requires either extensive technical capacity and bespoke data, or sources like the Google Maps API that quickly become prohibitively expensive to analyze thousands or millions of trips necessary for metropolitan-scale planning. These obstacles make it difficult for researchers, practitioners, and community advocates to develop an evidence base for more sustainable transportation and equitable accessibility. This article introduces a free, open-source minimally-congested driving time prediction model with minimal cost, data, and computational requirements. It trains and tests this model using the Los Angeles, California urban area as a case study by calculating naïve travel times from open data then developing a random forest model to predict true travel times as a function of those naïve times plus open data on turns and traffic controls. Validation shows that this method produces accurate, free, and simple travel time predictions, offering a superior middle-ground technique for urban planners.

\end{abstract}

\section{Introduction}

Travel time prediction underpins many transport planning processes and research problems. It is key to understanding urban accessibility, transport mode and route choice, and location decisions \citep{zhang2015gradient,jenelius2013travel}. Predicting congested travel times (i.e., when traffic congestion impedes flows) requires large volumes of real-time data on traffic conditions \citep[e.g.,][]{hou2018network}. Such data are proprietary, expensive, and beyond the reach of many planning practitioners and scholars \citep{carrion2012value,wang2011estimating}. This is usually not a problem for well-resourced organizations with highly-skilled labor---however, technical expertise, complex data and software requirements, and high costs pose insurmountable obstacles for many urban planning researchers, practitioners, and community advocates \citep{giles2022creating}.

Although typical \enquote{naïve} travel time prediction methods (which minimize travel distance or street segment traversal time) provide easy solutions, they ignore delays from turns and traffic controls and thus usually under-predict real-world driving travel time \citep{ludwig2023traffic,salonen2013modelling,yiannakoulias2013estimating}. However, as we will argue, minimally-congested travel time prediction offers a better middle ground of more-accurate predictions than naïve travel times do---yet much lower data and computing requirements than real-time traffic-aware congested travel time prediction.

To address this need for a middle ground, this article contributes a novel accurate, easy-to-use, and free method of minimally-congested driving travel time prediction. Our results show a substantial improvement over traditional, naïve methods of travel time prediction common in the urban planning literature. As we shall show in this article, across the Los Angeles urban area, our average trip's travel time prediction differs from Google's \enquote{gold standard} prediction by only 0.45 seconds. In contrast, simple---but common---naïve travel time prediction minimizing max-speed edge traversal times under-predicts by 183.55 seconds on average.

The rest of this article is organized as follows. First it reviews the state of the art in travel time prediction and then considers the less-sophisticated methods that are standard in the current planning literature. Next it describes our data sources, models, and validation techniques. Then it presents our findings, highlighting both the feasibility and quality of our predictions in relation to simple naïve predictions or difficult expensive predictions. Finally, it concludes with a discussion of implications for research and practice.

\section{Background}

Modern travel time prediction techniques tend to fall into one of two camps: (1) sophisticated, accurate, but difficult to execute; or (2) naïve, less-accurate, but simple to execute. The former is the state-of-the-art and has been the subject of much work in the recent computer science and engineering literatures. The latter tends to appear often in urban planning research and practice. Here we summarize the recent advances and current standards in these fields.

\subsection{State-of-the-Art Travel Time Prediction}

Recent studies in the computer science and engineering literatures propose a variety of prediction techniques with heavy computing and data requirements. They usually measure their prediction accuracy by mean absolute percentage error (MAPE), defined in \autoref{eq:mape}:

\begin{equation}
\label{eq:mape}
\text{MAPE} = \frac{100}{n} \sum^{n}_{i=1} \left|\frac{t_i - \hat{t_i}}{t_i}\right|
\end{equation}

where $n$ is the total number of trips, $t_i$ is trip $i$'s observed travel time, and $\hat{t_i}$ is trip $i$'s predicted travel time. Lower MAPEs indicate higher accuracy.  These studies usually yield MAPEs within roughly 10\% of observed driving times. Some researchers use alternative measures of accuracy, such as the percentage of over- or under-prediction \citep{jenelius2013travel}, the absolute mismeasurement in minutes \citep{chiabaut2021traffic}, or degrees of predictability \citep{li2019travel}.

These advanced travel time prediction models require massive data inputs as they are usually trained on millions or billions of disaggregate empirical travel time records. For example, \citet{hou2018network} use 1.5 billion GPS-based travel time records in deep learning models to predict travel time in 13 road segments in St. Louis, yielding a MAPE of 6.8\%. Using more than 100,000 trips from Windows phone GPS data, \citet{woodard2017predicting}'s technique achieves a MAPE of 10.1\% when predicting travel times. \citet{pamula2023estimation} use three months of video sensing data at a 5-minute temporal resolution in a deep learning model to predict travel times in Poland, yielding a 6.8\% MAPE.\@ Other studies use graph neural network models to predict travel times. For example, \citet{wang2023dynamic} use data from 100,000 Chinese ride-hailing trips in graph neural network and recurrent neural network models, yielding a MAPE of 15.4\%. \citet{vankdoth2023deep} achieve 3--4\% MAPEs using Q-Traffic and TaxiBJ data from Beijing and Chengdu in deep learning and graph neural network models.

Many of these studies focus on predicting travel times only for a specific street segment. For instance, \citet{sharmila2019svm} achieve a 10\% MAPE using GPS data in a support vector machine/particle filter model to predict travel times along specific arterials in Mumbai. \citet{chen2016multi}'s agent-based model uses data from GPS-equipped vehicles at 1-minute intervals across 123 days to achieve a MAPE under 9\% on a 95-mile freeway section in Virginia. Based on empirical travel time from GPS traces, road geometric features, and weather information, \citet{qiu2021machine} predict travel times using decision trees, random forests, extreme gradient boosting, and long short-term memory neural networks on the I-485 freeway in Charlotte, North Carolina, yielding MAPEs between 6--17\%.

As we have seen, these studies train or validate their models with a wide variety of bespoke data sources often collected from GPS devices or proprietary sources. The Google Maps API offers another common source. Though a black-box, many researchers use Google's travel times as the \enquote{gold standard} predictions of real-world travel times, given its ubiquity and accuracy and the challenges of otherwise directly obtaining sufficient empirical travel data \citep[e.g.,][]{goudarzi2018travel,stanojevic2019mapreuse,ludwig2023traffic}.

\subsection{Path Solving in Planning Research}

Central to all of the preceding travel time prediction research is the concept of \textit{path solving}: identifying the shortest path between an origin and destination in a spatial network model. In this case, the shortest path is defined as the path that minimizes travel time and could be realized methodologically in multiple ways. In the planning literature, studies variously minimize euclidean distance, network distance, network edge traversal time, free-flow travel time, or congested travel time. We discuss their trade-offs in this section.

The actual path solving methods used in urban planning research and practice tend to differ substantially from the state of the art travel time prediction in the engineering and computer science literatures. The preceding section's models require extensive technical capacity, instrumentation, and data. In general, the planning literature's implementations of path solving tend to be simpler to execute, but potentially naïve and less-accurate. For example, many accessibility studies employ merely a (very) rough proxy for travel time by minimizing euclidean distance traveled instead \citep[e.g.,][]{macfarlane2021modeling,pearsall2020locating}. This offers the substantial benefit of simplicity (no network model, travel time data, or routing algorithms are needed) but offers a poor estimate of access in terms of travel time.

Other studies improve on this by instead solving shortest paths by minimizing network distance traveled. These studies often use data and tools from Esri, OpenStreetMap, or the US Census Bureau to measure network distances between origins and destinations \citep[e.g.,][]{mckenzie2020urban, jiao2021measuring, nicoletti2023disadvantaged, logan2019evaluating, tsou2005accessibility}. This offers the benefit of more-realistic distances between origins and destinations, but does not account for travel speeds. Other studies refine this by incorporating speed limit data into the network model to solve shortest paths by traversal time \citep{kuai2017examining,williams2020parks,he2020evaluating,salonen2013modelling,scott2008role,neutens2010equity,wang2013planning}. Traversal time is similar to---but distinct from---uncongested travel time. The former merely minimizes the sum of the ratio of street segment length and speed limit, whereas the latter accounts for stops, signals, and turns. Some researchers sidestep the challenges of needing a network model and travel speed data by using secondary traffic analysis zone (TAZ) travel time data aggregated by metropolitan planning agencies \citep[e.g.,][]{grengs2010intermetropolitan,yan2021toward,levine2012does}. These data offer simplicity and real-world empricism, but their coarse-grained zone-to-zone aggregation obfuscates accurate point-to-point travel time predictions.

Finally, many planning scholars rely instead on the Google Maps API to obtain accurate origin-destination travel times and shortest paths \citep[e.g.,][]{fielbaum2021assessment,costa2021spatial, swayne2021integrating,hu2020estimating,cuervo2022dynamic,chen2020communities,hwang2024measuring}. As mentioned previously, Google travel times represent something of a \enquote{gold standard} in the literature, but come with drawbacks: the algorithms are closed-source and---for large batches of queries, such as for simulating metropolitan-scale trip taking---it can become prohibitively expensive and require many API queries. Nevertheless, evidence shows Google travel times offer a good proxy for observed real-world travel times \citep{lin2021impact,fu2023comparative,alsobky2020estimating,wang2011estimating}.

\subsection{Open Problem}

In summary, planning researchers today predict travel distances and times with a range of relatively simple techniques that minimize euclidean distance, network distance, street segment traversal time, TAZ-to-TAZ travel times, or Google travel times (for relatively few trips to keep costs down). These techniques are generally inexpensive and easy to implement. In contrast, today's state-of-the-art techniques in the computer science and engineering literatures require expensive data collection, private data, or much more complicated algorithms that planners are rarely trained to implement. In other words, it is expensive and challenging for the average planner to reproduce these state-of-the-art methods.

A better way would be to seek a middle ground between expensive, complicated, point-to-point empirical travel times and overly-simple naïve predictions. Such free empirical travel time predictions may not reflect congested travel times (which vary drastically throughout the day and week), but would provide a good prediction of minimally-congested travel times. This middle-ground method should meet three criteria. First, it should only use free software and free data, avoiding expensive API queries or bespoke GPS data collection. Second, it should be a simple and accessible method for urban planners without advanced technical skills. Third, it should provide a substantial improvement in accuracy or spatial resolution over naïve predictions such as minimizing Euclidean distance, network distance, street edge traversal time, and exsiting TAZ-to-TAZ travel times, and approach the accuracy of the state-of-art models. Meeting these three criteria, a middle ground should be inexpensive, easy-to-use, and reasonably accurate.

\section{Methods}

This article proposes a novel open-source, reusable, generalizable method\endnote{Our open-source tool is hosted at [REDACTED] for others to freely reuse.} to solve this problem. In short, it collects free open data plus a small amount of free data from the Google Maps API to train a local model to predict minimally-congested driving travel times with sparse data and simple computing hardware. \autoref{fig:workflow} shows a detailed workflow.

\begin{figure*}[bt!]
    \centering
    \includegraphics[width=1.0\textwidth]{fig_workflow.jpg}
    \caption{Detailed model workflow.}\label{fig:workflow}
\end{figure*}

\begin{table*}[tb!]
    \centering
    \caption{Traffic control elements (as identified by OpenStreetMap tags) present in the graph, demonstrating their sparseness relative to the total intersections and nodes in the graph.}\label{tab:traffic_control_counts}
    \begin{tabular}{lr}
        \toprule
        Element                        &   Count \\
        \midrule
        Crossing                       &  21,560 \\
        Stop sign                      &  26,304 \\
        Traffic signal                 &  15,262 \\
        Mini roundabout                &      44 \\
        Give way                       &     189 \\
        \midrule
        Total traffic control elements &  63,359 \\
        Total street intersections     & 127,093 \\
        Total nodes                    & 782,825 \\
        \bottomrule
    \end{tabular}
\end{table*}

\subsection{Input Data}

We define an implementation study area as the convex hull around the intersection of the Los Angeles County boundary and the Los Angeles urban area boundary from the Global Human Settlement Layer's Urban Center Database \citep{florczyk2019description, GHS2019}. This allows us to retain the main urbanized area without adjacent metropolitan areas (such as the Inland Empire). We then model the drivable street network within this study area from OpenStreetMap using the OSMnx package \citep{boeing_modeling_2025} and retaining the strongly connected component, to produce an unsimplified graph with 782,825 nodes, of which 127,093 are street intersections. The graph also contains 63,359 tagged traffic control elements. \autoref{tab:traffic_control_counts} summarizes these nodes' tagged traffic controls: these data are sparse and many true intersections lack traffic control information.

To generate origin-destination (OD) pairs for training a prediction model, we first over-sample 5,000,000 random node pairs from the street intersections and dead-ends in this graph. We then filter these down to realistic, minimally-congested trip patterns by using the most-recently released Uber movement data \citep{ubermovement2020}. These data derive from Uber trip GPS traces aggregated by tract-to-tract flow and hour of the day. We filter our OD pairs down to those that have a matching real-world trip ($n$ = 1,197,513) that occurred during the 03:00 hour ($n$ = 41,378) to best approximate minimally-congested traffic conditions. These Uber data are not a perfect measure of all real-world trips, but do validate the presence of travel demand between different OD pairs at different times of day.

Then we proxy \enquote{true travel times} by collecting travel times from the Google Maps Routes API, which has been used in numerous studies as a \enquote{gold standard} to proxy real-world travel times as discussed in the background section \citep[e.g.,][]{ludwig2023traffic, hu2020estimating, wang2011estimating, fu2023comparative, delmelle2019travel}. For each OD pair, the API provides the fastest network path, its travel time, and its length. The API allows users to predict travel times for trips departing in the future: the closer the departure time, the more accurate the prediction. Accordingly, we set the departure time to 03:00 and performed the query immediately beforehand (between 02:30--02:40) on 31 January and 1 February 2024. We used Google's \enquote{BEST\_GUESS} traffic-aware model to predict its \enquote{duration\_in\_traffic} travel time. The API was unable to solve 18 OD pairs' routes, resulting in 41,360 OD pairs with a true travel time, which we use as the response in our prediction model.

\begin{figure*}[tb!]
    \centering
    \includegraphics[width=1.0\textwidth]{fig_turns_definition.jpg}
    \caption{Angular definition of turns in the prediction model.}\label{fig:turns_definition}
\end{figure*}

\subsection{Model Specification and Tuning}

Conceptually, our travel time prediction model has two steps. First, we calculate \enquote{naïve} travel times across a set of trips using open data and open-source software. Second, we train a random forest (regression) model to predict our true travel times from our naïve travel times plus a set of covariates.

To calculate the naïve travel times for step one, we solve each OD pair's shortest path using Dijkstra's algorithm to minimize edge traversal time at the speed limit. Then we count the number of traffic control elements across the 5 types in \autoref{tab:traffic_control_counts} (stop signs, traffic signals, pedestrian crossings, give ways, and mini roundabouts), and the number of turns across the 5 types in \autoref{fig:turns_definition} (left, slight left, right, slight right, and u-turn), that were encountered along each OD pair's naïve route. Next we specify a travel time prediction model to predict an OD pair's true travel time (proxied by Google travel time) as a function of its naïve travel time plus these counts of each type of traffic control element. This model's specification is generalized by \autoref{eq:prediction_model}:

\begin{equation}
\label{eq:prediction_model}
y = f(X) + \epsilon
\end{equation}

where $f$ is a prediction model to be trained on our data, $y$ is a length-$n$ response vector (true travel time), $X$ is a matrix of $n$ observations on 11 predictors (naïve travel time plus counts of the 5 types of traffic control element encountered and counts of the 5 types of turn directions encountered), and $\epsilon$ is random error.

We train candidate models of this specification using several algorithms: decision trees, random forest, gradient boosting, and AdaBoost. A set of hyperparameters controls this algorithmic training. To tune each's hyperparameters for optimal performance, we split our data into a standard 80/20 training/test split then conduct a randomized grid search with 5-fold cross-validation to minimize the mean absolute error (MAE), defined by \autoref{eq:mae}:

\begin{equation}
\label{eq:mae}
\text{MAE} = \frac{\sum^{n}_{i=1} \left|{y_i - \hat{y_i}}\right|}{n}
\end{equation}

where $n$ is the total trip count, $y_i$ is trip $i$'s true travel time, and $\hat{y_i}$ is $i$'s predicted travel time.

\subsection{Model Selection and Validation}

Once we have our candidate models tuned and trained, we select our final prediction model and validate the out-of-sample predictions against true travel times via six accuracy indicators. First, we calculate the MAPE, following \autoref{eq:mape}. Second, we calculate the MAE, following \autoref{eq:mae}. Third, we calculate the mean squared error (MSE), which is more sensitive to outliers than MAE or MAPE, following \autoref{eq:mse} (with the same variables as defined for \autoref{eq:mae}):

\begin{equation}
\label{eq:mse}
\text{MSE} = \frac{\sum^{n}_{i=1} (y_i - \hat{y_i})^2}{n}
\end{equation}

Fourth, we perform difference-in-means ($\delta$) $t$-tests to determine whether our predicted travel times are statistically significantly different (at the 95\% confidence level) from the true travel times, to detect absolute systematic prediction bias. Despite the large sample size, we expect insignificant $t$-statistics if the predicted travel times' distribution closely matches the true travel times' distribution. Fifth, we calculate the average pairwise ratio (APR) of our predicted travel times and true travel times, to detect relative systematic prediction bias, as defined by \autoref{eq:apr} (with the same variables as defined for \autoref{eq:mae}):

\begin{equation}
\label{eq:apr}
\text{APR} = \frac{\sum^{n}_{i=1}\frac{y_i}{\hat{y_i}}}{n}
\end{equation}

Sixth and finally, we calculate the coefficient of determination, $R^2$, to measure our model's ability to explain observed travel time variation.

\section{Results}

\subsection{Optimized Hyperparameterization}

After tuning, the four model training algorithms perform similarly across most---but not all---of the accuracy indicators (\autoref{tab:validation_results}). They fall roughly in a similar range for MAPE (7.8--9.0\%), MAE (71.8--79.7 seconds), MSE (12,140--13,517 square seconds), APR (0.99--1.01), and $R^2$ (0.93), demonstrating the robustness of our model to algorithmic particulars. However, the random forest and decision tree models exhibit much lower absolute systematic prediction bias ($\delta$ = 0.45 and 0.44 seconds, respectively) than the gradient boosting and AdaBoost models do (-19.3 and -9.7 seconds, respectively). In other words, all these models have comparable mean errors---but the average random forest and decision tree predictions are statistically insignificantly different from the average true travel time, whereas gradient boosting and AdaBoost significantly under-predict it.

Therefore, we select the random forest model as our \enquote{final} travel time prediction model because it predicts better overall (than the decision tree model) and better avoids systematic under-prediction (than the gradient boosting and AdaBoost models). This final model trains an ensemble of decision trees to predict unobserved response values by essentially dividing the data into boxes then making predictions based on the means of those boxes. Its optimized hyperparameterization uses 400 decision trees, random sampling with replacement in each decision tree, a maximum decision tree depth of 10, use of all available input explanatory features at each split, a requirement of at least two samples to split at a decision node, and the default settings that require at least one sample at a leaf node and apply equal sample weighting.

Finally, we check this final model for overfitting by conducting another 5-fold cross-validation across the whole sample using the tuned hyperparameters. The resulting five MAE values (75.3, 74.5, 73.5, 73.3, 74.6) are all very close to each other, indicating that the model is not overfitted and its hyperparameters are not overly specific to the training set.

\subsection{Model Performance and Validation}

\begin{table*}[tb!]
    \centering\small
    \caption{Out-of-sample prediction accuracy of our chosen model (random forest, bold) versus the initial naïve travel time model and the discarded alternative models, all validated against the corresponding true travel times. $n$ = 8,272 for each. The six accuracy indicators are (1) MAPE \%, (2) MAE in seconds, (3) MSE in square seconds, (4) difference-in-means ($\delta$) in seconds and its corresponding $t$-test's $p$-value, (5) APR, and (6) $R^2$. See methods for definitions.}\label{tab:validation_results}
    \begin{tabular}{lrrrrrrr}
        \toprule
        Model               & MAPE  & MAE    & MSE      & $\delta$ & $p$  & APR  & $R^2$ \\
        \midrule
        Initial naïve       & 21.13 & 183.55 & 48155.43 &  -182.71 & <0.01 & 0.79 & 0.74  \\
        \textbf{Random forest}       &  \textbf{8.43} &  \textbf{75.24} & \textbf{12140.14} &     \textbf{0.45} &  \textbf{0.71} & \textbf{1.01} & \textbf{0.93}  \\
        Gradient boosting   &  7.84 &  71.81 & 12572.83 &   -19.30 & <0.01 & 0.99 & 0.93  \\
        Decision trees      &  8.96 &  79.74 & 13517.03 &     0.44 &  0.73 & 1.01 & 0.93  \\
        AdaBoost            &  8.21 &  74.05 & 12416.08 &    -9.73 & <0.01 & 1.00 & 0.93  \\
        \bottomrule
    \end{tabular}
\end{table*}

Compared to the initial naïve travel time calculation, our travel time prediction model exhibits substantial out-of-sample improvement (\autoref{tab:validation_results}). Our model produces a MAPE of 8.4\%, in line with the \textasciitilde10\% MAPEs seen in the state-of-the-art travel time prediction literature, but without their extensive and expensive input data requirements. In comparison, our initial naïve travel time calculation produces a much worse MAPE of 21.1\%. Whereas the naïve travel time's MAE is 183.6 seconds, our model's predicted travel times' MAE is just 75.2 seconds---an improvement by a factor of 2.4. Similarly for MSE, our model improved by a factor of 4.0.

The $t$-test reveals significant differences between the initial naïve travel time calculations and the true travel times: the $\delta$ of -183.6 seconds corresponds to $p$ < 0.01. In other words, the naïve travel time under-predicts true travel time by over 3 minutes. However, the $t$-test reveals insignificant differences between our model's out-of-sample predictions and the true travel times: the $\delta$ of 0.45 seconds corresponds to a $p$ value of 0.71. That is, our prediction model over-predicts by less than half a second on average, which is statistically insignificantly different from zero. If we reconsider the aforementioned MAEs in light of these differences-in-means, we can see that the initial naïve travel time calculations significantly and consistently under-predict travel time, but our prediction model shows no such directional bias: its random error averages out between (smaller absolute) over-and under-prediction.

The APR offers another lens on this finding. On average across the OD pairs, the initial naïve travel time calculation under-predicts true travel time by 21\%, but our prediction model over-predicts it by just 1\%. Our model also explains more of the variation in travel time: its $R^2$ of 0.93 is substantially higher than the 0.74 $R^2$ of the initial naïve travel time calculation. In sum, each of our six accuracy indicators demonstrates that our prediction model drastically improves on naïve travel time calculations---without needing extensive, expensive input data or advanced deep learning software---and offers much more accurate travel time predictions.

\section{Discussion}

The planning literature shows that planners often use driving travel time prediction techniques far below the state-of-the-art due to cost, data, and technical capacity constraints. This study investigated if a better middle-ground travel time prediction method was feasible. It identified three criteria for success: (1) it should use free software and data and avoid bespoke sensor data collection; (2) it should be easy and accessible to use; (3) it should offer better accuracy than naïve predictions (e.g., minimizing Euclidean distance, network distance, street edge traversal time) and better spatial resolution than zone-to-zone travel times.

Our results show that our proposed method satisfies these criteria to offer an important middle-ground contribution. First, it relies only on open-source Python software, OpenStreetMap data, and a small free amount of Google travel time training data. Second, our model is easy to use: it does not require a complex computing environment suited for deep learning's extensive data and processing requirements. Rather, our model uses out-of-the-box tools that can be set up in seconds on a standard consumer-grade computer by anyone familiar with Python, the world's most popular programming language. Third, our model is accurate: its MAPE (8.4\%) is much lower than that of the naïve model and in line with state-of-the-art models (\textasciitilde3--17\%) with extensive data and computing requirements.

This middle ground is not necessarily for computer scientists, high-end labs with top-of-the-line computing hardware, or well-resourced agencies with extensive data budgets. Rather, it empowers the scholars and practitioners who need it the most---those working on the frontlines of urban planning and policymaking. The literature shows that these scholars and practitioners often rely on simple but inaccurate routing models---such as minimizing Euclidean distance, network distance, or edge traversal time---when they lack the technical expertise, computing equipment, or extensive data needed to implement the literature's cutting-edge models. However, this study demonstrates how these naïve methods systematically under-predict real-world travel times. Our model addresses this problem by incorporating sparse open data on traffic control elements and turns into the prediction to achieve an accuracy in line with state-of-the-art methods---but without their data needs or computing requirements. In other words, our model does not replace the state-of-the-art congested-traffic methods for those with extensive resources available to implement them, but rather offers far more accurate predictions for urban planners who would otherwise fall back on simpler naïve models. Inaccurate travel times skew empirical understandings and mislead planning interventions. Our model represents an important middle-ground contribution for urban planning scholarship and evidence-informed practitioner interventions.

As demonstrated, this model supports high-resolution point-to-point travel time predictions across a large metropolitan area. Our implementation focused on Los Angeles but is not inherently tied to it, and future work should emphasize its generalizability in cities with potentially sparser or lower-quality open data. We trained this model as a proof-of-concept for minimally-congested times of day, but the same concept can be extended with similar training data for any other time of day if congestion data exist. Future research should also expand the kinds of training and validation data. Although used by billions of people around the world as the public's \enquote{best available} source of travel time prediction, Google travel time remains a black box based on users' GPS data. Future work can use other empirical travel time data to further train and validate the model.

\section{Conclusion}

Travel time prediction is central to questions of urban accessibility, mode and route choice, and individuals' location decisions. True congested travel times vary drastically throughout the day and require large volumes of real-time or proprietary data, as well as complex algorithms, to model. These technical challenges and costs present a hurdle for many urban planners, who often turn to simpler models with lower and often free data and computing requirements. These traditional naïve methods may be easy to implement, but they produce wildly inaccurate predictions.

This article introduced a better middle-ground method to simply but accurately predict minimally-congested driving travel time using free data. It improves on traditional, common, naïve predictions by training on a small one-off collection of free but proprietary high-quality Google data on travel times. Also of note is the sparseness of our open data: OpenStreetMap contains only sporadic information on traffic controls' presence. Even so, our prediction model demonstrates very high accuracy. This offers planning practitioners and scholars a better method to predict travel times for free with much better accuracy than traditional naïve methods offered.

\section*{Data Availability Statement}

The data that support the findings of this study are available at [URL REDACTED].
%https://github.com/gboeing/travel-time-prediction

\section*{Conflict of Interest Statement}

The authors have no relevant financial or non-financial competing interests to report.

\section*{Acknowledgments}

[REDACTED]
%The authors wish to thank Youngseo Kweon and Jaehyun Ha for additional research assistance.

% print the footnotes as endnotes, if any exist
\IfFileExists{\jobname.ent}{\theendnotes}{}

% print the bibliography
\setlength{\bibsep}{0.00cm plus 0.05cm} % no space between items
\bibliographystyle{apalike}
\bibliography{references}

\end{document}
