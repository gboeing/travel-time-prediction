{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0d7ce87b4903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "file_path = \"../Data/\"\n",
    "output_file_path = file_path + \"Output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163fe5da854c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the freeflow result based on non-simplified graph\n",
    "ff_df = pd.read_csv(\n",
    "    output_file_path\n",
    "    + \"result0226/\"\n",
    "    + \"freeflow_OD3am_all_googlerouteapi_new_graph_new_turn_control_slight.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b86c987fa24421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the google api result\n",
    "gg_df_result_all = pd.read_csv(output_file_path + \"googlerouteapi2024allresult.csv\")\n",
    "# merge the freeflow travel time and google travel time into one dataframe\n",
    "df = ff_df.merge(gg_df_result_all, left_on=[\"oid\", \"did\"], right_on=[\"oid\", \"did\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e1ea3785a546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff\"] = df[\"duration\"] - df[\"travel_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e9ca6410808d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0de26baffbe160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test set\n",
    "train1, test1 = train_test_split(df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970d7297d88c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train1[\"duration\"]\n",
    "x = train1[\n",
    "    [\n",
    "        \"signal_count\",\n",
    "        \"stop_count\",\n",
    "        \"crossing_count\",\n",
    "        \"give_way_count\",\n",
    "        \"mini_roundabout_count\",\n",
    "        \"left_count\",\n",
    "        \"slight_left_count\",\n",
    "        \"right_count\",\n",
    "        \"slight_right_count\",\n",
    "        \"u_count\",\n",
    "        \"travel_time\",\n",
    "    ]\n",
    "]\n",
    "x_test = test1[\n",
    "    [\n",
    "        \"signal_count\",\n",
    "        \"stop_count\",\n",
    "        \"crossing_count\",\n",
    "        \"give_way_count\",\n",
    "        \"mini_roundabout_count\",\n",
    "        \"left_count\",\n",
    "        \"slight_left_count\",\n",
    "        \"right_count\",\n",
    "        \"slight_right_count\",\n",
    "        \"u_count\",\n",
    "        \"travel_time\",\n",
    "    ]\n",
    "]\n",
    "y_test = test1[\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c463b3317e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the default Random forest Regression to the dataset\n",
    "regressor = RandomForestRegressor()\n",
    "# Fit the regressor with x and y data\n",
    "regressor.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b483f91826353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the result\n",
    "predictions = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf1dbc47fff9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors = abs(predictions - y_test)\n",
    "print(\"Average baseline error:\", round(np.mean(Errors), 3), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff362d34b2a89455",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[\"rf_predict_default\"] = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831504d06d1a1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the default random forest model: mean square error and r-squared\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab115e8dfbb94b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Freeflow travel time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cac281d4eded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the default freeflow model: mean square error and r-squared\n",
    "mse = mean_squared_error(y_test, test1[\"travel_time\"])\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "r2 = r2_score(y_test, test1[\"travel_time\"])\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f905a643df7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = abs(y_test - test1[\"travel_time\"])\n",
    "print(f\"Average Error: {np.mean(errors):0.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3567f1a6bff399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = abs(y_test - test1[\"travel_time\"])\n",
    "print(f\"Median Error: {np.median(errors):0.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c1515700aa1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = 100 * np.mean(errors / y_test)\n",
    "accuracy = 100 - mape\n",
    "print(f\"Average Accuracy = {accuracy:0.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbf70425bee944",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = 100 * np.median(errors / y_test)\n",
    "accuracy = 100 - mape\n",
    "print(f\"Average Accuracy = {accuracy:0.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850735626c6ab38",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Try modelling using the difference as the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb542e70cb2e1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try modelling using the difference\n",
    "y = train1[\"diff\"]\n",
    "x = train1[\n",
    "    [\n",
    "        \"signal_count\",\n",
    "        \"stop_count\",\n",
    "        \"crossing_count\",\n",
    "        \"give_way_count\",\n",
    "        \"mini_roundabout_count\",\n",
    "        \"left_count\",\n",
    "        \"slight_left_count\",\n",
    "        \"right_count\",\n",
    "        \"slight_right_count\",\n",
    "        \"u_count\",\n",
    "    ]\n",
    "]\n",
    "y_test = test1[\"diff\"]\n",
    "x_test = test1[\n",
    "    [\n",
    "        \"signal_count\",\n",
    "        \"stop_count\",\n",
    "        \"crossing_count\",\n",
    "        \"give_way_count\",\n",
    "        \"mini_roundabout_count\",\n",
    "        \"left_count\",\n",
    "        \"slight_left_count\",\n",
    "        \"right_count\",\n",
    "        \"slight_right_count\",\n",
    "        \"u_count\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6e6ddbd0c5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(random_state=123)\n",
    "regressor.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a022ef0210c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927312bc49a495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors = abs(predictions - y_test)\n",
    "print(\"Average baseline error:\", round(np.mean(Errors), 3), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea292935c2ff165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba509e5a0e9a248",
   "metadata": {},
   "source": [
    "### It is a lot worse than modelling the google travel time, so we abandon the model that use the difference as the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513753c6989ce219",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hyper tuning of random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c03fd86b9f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd995b0787f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameters currently in use:\\n\")\n",
    "pprint(regressor.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b221ca34482a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and randomized grid of hyper parameters\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=1000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"sqrt\", \"log2\", None]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, None]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c0b4257d75a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train1[\"duration\"]\n",
    "train_features = train1[\n",
    "    [\n",
    "        \"signal_count\",\n",
    "        \"stop_count\",\n",
    "        \"crossing_count\",\n",
    "        \"give_way_count\",\n",
    "        \"mini_roundabout_count\",\n",
    "        \"left_count\",\n",
    "        \"slight_left_count\",\n",
    "        \"right_count\",\n",
    "        \"slight_right_count\",\n",
    "        \"u_count\",\n",
    "        \"travel_time\",\n",
    "    ]\n",
    "]\n",
    "test_features = test1[\n",
    "    [\n",
    "        \"signal_count\",\n",
    "        \"stop_count\",\n",
    "        \"crossing_count\",\n",
    "        \"give_way_count\",\n",
    "        \"mini_roundabout_count\",\n",
    "        \"left_count\",\n",
    "        \"slight_left_count\",\n",
    "        \"right_count\",\n",
    "        \"slight_right_count\",\n",
    "        \"u_count\",\n",
    "        \"travel_time\",\n",
    "    ]\n",
    "]\n",
    "test_labels = test1[\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6159932f061ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor(random_state=123)\n",
    "# Random search of parameters, using 5 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=123,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21622c68cb285e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best hyper parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa78142323cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print(\"Model Performance\")\n",
    "    print(f\"Average Error: {np.mean(errors):0.4f} seconds.\")\n",
    "    print(f\"Accuracy = {accuracy:0.2f}%.\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84ef8eb6ff173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "base_model.fit(train_features, train_labels)\n",
    "base_accuracy = evaluate(base_model, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e13c4f3f59a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = RandomForestRegressor(\n",
    "    n_estimators=600,\n",
    "    random_state=123,\n",
    "    min_samples_split=2,\n",
    "    max_features=None,\n",
    "    max_depth=10,\n",
    "    bootstrap=True,\n",
    ")\n",
    "best_random.fit(train_features, train_labels)\n",
    "random_accuracy = evaluate(best_random, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5de8261832e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_random.predict(x_test)\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf662f63aa93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[\"best_rf_predict\"] = best_random.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c9e376cc6ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test\n",
    "stats.ttest_rel(test1[\"best_rf_predict\"], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7f7b9a4efdc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "test1.to_csv(output_file_path + \"result0331/\" + \"test1_best_rf_predict0331.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
